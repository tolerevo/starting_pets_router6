{"ast":null,"code":"import { stringToHeaders } from \"headers-polyfill\";\nfunction parseContentHeaders(headersString) {\n  const headers = stringToHeaders(headersString);\n  const contentType = headers.get(\"content-type\") || \"text/plain\";\n  const disposition = headers.get(\"content-disposition\");\n  if (!disposition) {\n    throw new Error('\"Content-Disposition\" header is required.');\n  }\n  const directives = disposition.split(\";\").reduce((acc, chunk) => {\n    const [name2, ...rest] = chunk.trim().split(\"=\");\n    acc[name2] = rest.join(\"=\");\n    return acc;\n  }, {});\n  const name = directives.name?.slice(1, -1);\n  const filename = directives.filename?.slice(1, -1);\n  return {\n    name,\n    filename,\n    contentType\n  };\n}\nfunction parseMultipartData(data, headers) {\n  const contentType = headers?.get(\"content-type\");\n  if (!contentType) {\n    return void 0;\n  }\n  const [, ...directives] = contentType.split(/; */);\n  const boundary = directives.filter(d => d.startsWith(\"boundary=\")).map(s => s.replace(/^boundary=/, \"\"))[0];\n  if (!boundary) {\n    return void 0;\n  }\n  const boundaryRegExp = new RegExp(`--+${boundary}`);\n  const fields = data.split(boundaryRegExp).filter(chunk => chunk.startsWith(\"\\r\\n\") && chunk.endsWith(\"\\r\\n\")).map(chunk => chunk.trimStart().replace(/\\r\\n$/, \"\"));\n  if (!fields.length) {\n    return void 0;\n  }\n  const parsedBody = {};\n  try {\n    for (const field of fields) {\n      const [contentHeaders, ...rest] = field.split(\"\\r\\n\\r\\n\");\n      const contentBody = rest.join(\"\\r\\n\\r\\n\");\n      const {\n        contentType: contentType2,\n        filename,\n        name\n      } = parseContentHeaders(contentHeaders);\n      const value = filename === void 0 ? contentBody : new File([contentBody], filename, {\n        type: contentType2\n      });\n      const parsedValue = parsedBody[name];\n      if (parsedValue === void 0) {\n        parsedBody[name] = value;\n      } else if (Array.isArray(parsedValue)) {\n        parsedBody[name] = [...parsedValue, value];\n      } else {\n        parsedBody[name] = [parsedValue, value];\n      }\n    }\n    return parsedBody;\n  } catch (error) {\n    return void 0;\n  }\n}\nexport { parseMultipartData };","map":{"version":3,"mappings":"AAAA,SAASA,uBAAuB;AAgBhC,SAASC,oBAAoBC,eAA6C;EACxE,MAAMC,UAAUH,gBAAgBE,aAAa;EAC7C,MAAME,cAAcD,QAAQE,IAAI,cAAc,KAAK;EACnD,MAAMC,cAAcH,QAAQE,IAAI,qBAAqB;EAErD,IAAI,CAACC,aAAa;IAChB,MAAM,IAAIC,MAAM,2CAA2C;EAC7D;EAEA,MAAMC,aAAaF,YAAYG,MAAM,GAAG,EAAEC,OAAO,CAACC,KAAKC,UAAU;IAC/D,MAAM,CAACC,OAAM,GAAGC,IAAI,IAAIF,MAAMG,KAAK,EAAEN,MAAM,GAAG;IAC9CE,IAAIE,KAAI,IAAIC,KAAKE,KAAK,GAAG;IACzB,OAAOL;EACT,GAAG,CAAC,CAAgC;EAEpC,MAAME,OAAOL,WAAWK,MAAMI,MAAM,GAAG,EAAE;EACzC,MAAMC,WAAWV,WAAWU,UAAUD,MAAM,GAAG,EAAE;EAEjD,OAAO;IACLJ;IACAK;IACAd;EACF;AACF;AAMO,SAASe,mBACdC,MACAjB,SACe;EACf,MAAMC,cAAcD,SAASE,IAAI,cAAc;EAE/C,IAAI,CAACD,aAAa;IAChB,OAAO;EACT;EAEA,MAAM,GAAG,GAAGI,UAAU,IAAIJ,YAAYK,MAAM,KAAK;EACjD,MAAMY,WAAWb,WACdc,OAAQC,KAAMA,EAAEC,WAAW,WAAW,CAAC,EACvCC,IAAKC,KAAMA,EAAEC,QAAQ,cAAc,EAAE,CAAC,EAAE,CAAC;EAE5C,IAAI,CAACN,UAAU;IACb,OAAO;EACT;EAEA,MAAMO,iBAAiB,IAAIC,OAAO,MAAMR,QAAQ,EAAE;EAClD,MAAMS,SAASV,KACZX,MAAMmB,cAAc,EACpBN,OAAQV,SAAUA,MAAMY,WAAW,MAAM,KAAKZ,MAAMmB,SAAS,MAAM,CAAC,EACpEN,IAAKb,SAAUA,MAAMoB,UAAU,EAAEL,QAAQ,SAAS,EAAE,CAAC;EAExD,IAAI,CAACG,OAAOG,QAAQ;IAClB,OAAO;EACT;EAEA,MAAMC,aAA0C,CAAC;EAEjD,IAAI;IACF,WAAWC,SAASL,QAAQ;MAC1B,MAAM,CAACM,gBAAgB,GAAGtB,IAAI,IAAIqB,MAAM1B,MAAM,UAAU;MACxD,MAAM4B,cAAcvB,KAAKE,KAAK,UAAU;MACxC,MAAM;QAAEZ;QAAac;QAAUL;MAAK,IAClCZ,oBAAoBmC,cAAc;MAEpC,MAAME,QACJpB,aAAa,SACTmB,cACA,IAAIE,KAAK,CAACF,WAAW,GAAGnB,UAAU;QAAEsB,MAAMpC;MAAY,CAAC;MAE7D,MAAMqC,cAAcP,WAAWrB,IAAI;MAEnC,IAAI4B,gBAAgB,QAAW;QAC7BP,WAAWrB,IAAI,IAAIyB;MACrB,WAAWI,MAAMC,QAAQF,WAAW,GAAG;QACrCP,WAAWrB,IAAI,IAAI,CAAC,GAAG4B,aAAaH,KAAK;MAC3C,OAAO;QACLJ,WAAWrB,IAAI,IAAI,CAAC4B,aAAaH,KAAK;MACxC;IACF;IAEA,OAAOJ;EACT,SAASU,OAAO;IACd,OAAO;EACT;AACF","names":["stringToHeaders","parseContentHeaders","headersString","headers","contentType","get","disposition","Error","directives","split","reduce","acc","chunk","name","rest","trim","join","slice","filename","parseMultipartData","data","boundary","filter","d","startsWith","map","s","replace","boundaryRegExp","RegExp","fields","endsWith","trimStart","length","parsedBody","field","contentHeaders","contentBody","value","File","type","parsedValue","Array","isArray","error"],"sources":["/Users/ditole/Desktop/projects/pets-store/node_modules/msw/src/core/utils/internal/parseMultipartData.ts"],"sourcesContent":["import { stringToHeaders } from 'headers-polyfill'\nimport { DefaultRequestMultipartBody } from '../../handlers/RequestHandler'\n\ninterface ParsedContentHeaders {\n  name: string\n  filename?: string\n  contentType: string\n}\n\ninterface ContentDispositionDirective {\n  [key: string]: string | undefined\n  name: string\n  filename?: string\n  'form-data': string\n}\n\nfunction parseContentHeaders(headersString: string): ParsedContentHeaders {\n  const headers = stringToHeaders(headersString)\n  const contentType = headers.get('content-type') || 'text/plain'\n  const disposition = headers.get('content-disposition')\n\n  if (!disposition) {\n    throw new Error('\"Content-Disposition\" header is required.')\n  }\n\n  const directives = disposition.split(';').reduce((acc, chunk) => {\n    const [name, ...rest] = chunk.trim().split('=')\n    acc[name] = rest.join('=')\n    return acc\n  }, {} as ContentDispositionDirective)\n\n  const name = directives.name?.slice(1, -1)\n  const filename = directives.filename?.slice(1, -1)\n\n  return {\n    name,\n    filename,\n    contentType,\n  }\n}\n\n/**\n * Parses a given string as a multipart/form-data.\n * Does not throw an exception on an invalid multipart string.\n */\nexport function parseMultipartData<T extends DefaultRequestMultipartBody>(\n  data: string,\n  headers?: Headers,\n): T | undefined {\n  const contentType = headers?.get('content-type')\n\n  if (!contentType) {\n    return undefined\n  }\n\n  const [, ...directives] = contentType.split(/; */)\n  const boundary = directives\n    .filter((d) => d.startsWith('boundary='))\n    .map((s) => s.replace(/^boundary=/, ''))[0]\n\n  if (!boundary) {\n    return undefined\n  }\n\n  const boundaryRegExp = new RegExp(`--+${boundary}`)\n  const fields = data\n    .split(boundaryRegExp)\n    .filter((chunk) => chunk.startsWith('\\r\\n') && chunk.endsWith('\\r\\n'))\n    .map((chunk) => chunk.trimStart().replace(/\\r\\n$/, ''))\n\n  if (!fields.length) {\n    return undefined\n  }\n\n  const parsedBody: DefaultRequestMultipartBody = {}\n\n  try {\n    for (const field of fields) {\n      const [contentHeaders, ...rest] = field.split('\\r\\n\\r\\n')\n      const contentBody = rest.join('\\r\\n\\r\\n')\n      const { contentType, filename, name } =\n        parseContentHeaders(contentHeaders)\n\n      const value =\n        filename === undefined\n          ? contentBody\n          : new File([contentBody], filename, { type: contentType })\n\n      const parsedValue = parsedBody[name]\n\n      if (parsedValue === undefined) {\n        parsedBody[name] = value\n      } else if (Array.isArray(parsedValue)) {\n        parsedBody[name] = [...parsedValue, value]\n      } else {\n        parsedBody[name] = [parsedValue, value]\n      }\n    }\n\n    return parsedBody as T\n  } catch (error) {\n    return undefined\n  }\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}